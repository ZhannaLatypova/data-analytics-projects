#!/usr/bin/env python
# coding: utf-8

# <div class="alert alert-block alert-info">
# <font size="5">
# <center><b>АНАЛИЗ ПОВЕДЕНИЯ ПОЛЬЗОВАТЕЛЕЙ МОБИЛЬНОГО ПРИЛОЖЕНИЯ</b></center>
# </font>
#     </div> 

# <span class="mark">**Описание**</span> 
# 
# Вы работаете в стартапе, который продаёт продукты питания. Нужно разобраться, как ведут себя пользователи вашего мобильного приложения.
# 
# Изучите воронку продаж. Узнайте, как пользователи доходят до покупки. Сколько пользователей доходит до покупки, а сколько — «застревает» на предыдущих шагах? На каких именно?
# 
# После этого исследуйте результаты A/A/B-эксперимента. Дизайнеры захотели поменять шрифты во всём приложении, а менеджеры испугались, что пользователям будет непривычно. Договорились принять решение по результатам A/A/B-теста. Пользователей разбили на 3 группы: 2 контрольные со старыми шрифтами и одну экспериментальную — с новыми. Выясните, какой шрифт лучше.
# 
# Создание двух групп A вместо одной имеет определённые преимущества. Если две контрольные группы окажутся равны, вы можете быть уверены в точности проведенного тестирования. Если же между значениями A и A будут существенные различия, это поможет обнаружить факторы, которые привели к искажению результатов. Сравнение контрольных групп также помогает понять, сколько времени и данных потребуется для дальнейших тестов.
# 
# В случае общей аналитики и A/A/B-эксперимента работайте с одними и теми же данными. В реальных проектах всегда идут эксперименты. Аналитики исследуют качество работы приложения по общим данным, не учитывая принадлежность пользователей к экспериментам.
# 
# <span class="mark"> **Описание данных**</span>
# 
# Каждая запись в логе — это действие пользователя, или событие.
# 
# - `EventName` — название события;
# - `DeviceIDHash` — уникальный идентификатор пользователя;
# - `EventTimestamp` — время события;
# - `ExpId` — номер эксперимента: 246 и 247 — контрольные группы, а 248 — экспериментальная.
# 
# 
# <span class="mark">**Оглавление**</span>
# 
# <font color='saddlebrown'> **[1. Изучение исходных данных](#num1)**</font>
#     
# <font color='saddlebrown'>**[2. Предобработка данных](#num2)**</font>
#     
# - Замените названия столбцов на удобные для вас;
# - Проверьте пропуски и типы данных. Откорректируйте, если нужно;
# - Добавьте столбец даты и времени, а также отдельный столбец дат;    
# - Сколько всего событий в логе?
# - Сколько всего пользователей в логе?
# - Сколько в среднем событий приходится на пользователя?
# - Данными за какой период вы располагаете? Найдите максимальную и минимальную дату. Постройте гистограмму по дате и времени. Можно ли быть уверенным, что у вас одинаково полные данные за весь период? Технически в логи новых дней по некоторым пользователям могут «доезжать» события из прошлого — это может «перекашивать данные». Определите, с какого момента данные полные и отбросьте более старые. Данными за какой период времени вы располагаете на самом деле?
# - Много ли событий и пользователей вы потеряли, отбросив старые данные?
# - Проверьте, что у вас есть пользователи из всех трёх экспериментальных групп.
# 
# <font color='saddlebrown'>**[3. Воронка событий](#num3)**</font>
#     
# - Посмотрите, какие события есть в логах, как часто они встречаются. Отсортируйте события по частоте.
# - Посчитайте, сколько пользователей совершали каждое из этих событий. Отсортируйте события по числу пользователей. Посчитайте долю пользователей, которые хоть раз совершали событие.
# - Предположите, в каком порядке происходят события. Все ли они выстраиваются в последовательную цепочку? Их не нужно учитывать при расчёте воронки.
# - По воронке событий посчитайте, какая доля пользователей проходит на следующий шаг воронки (от числа пользователей на предыдущем). То есть для последовательности событий A → B → C посчитайте отношение числа пользователей с событием B к количеству пользователей с событием A, а также отношение числа пользователей с событием C к количеству пользователей с событием B.
# - На каком шаге теряете больше всего пользователей?
# - Какая доля пользователей доходит от первого события до оплаты?
# 
# <font color='saddlebrown'>**[4. Результаты эксперимента](#num4)**</font>
#     
# - Сколько пользователей в каждой экспериментальной группе?
# -Есть 2 контрольные группы для А/А-эксперимента, чтобы проверить корректность всех механизмов и расчётов. Проверьте, находят ли статистические критерии разницу между выборками 246 и 247.
# - Выберите самое популярное событие. Посчитайте число пользователей, совершивших это событие в каждой из контрольных групп. Посчитайте долю пользователей, совершивших это событие. Проверьте, будет ли отличие между группами статистически достоверным. Проделайте то же самое для всех других событий (удобно обернуть проверку в отдельную функцию). Можно ли сказать, что разбиение на группы работает корректно?
# - Аналогично поступите с группой с изменённым шрифтом. Сравните результаты с каждой из контрольных групп в отдельности по каждому событию. Сравните результаты с объединённой контрольной группой. Какие выводы из эксперимента можно сделать?
# - Какой уровень значимости вы выбрали при проверке статистических гипотез выше? Посчитайте, сколько проверок статистических гипотез вы сделали. При уровне значимости 0.1 каждый десятый раз можно получать ложный результат. Какой уровень значимости стоит применить? Если вы хотите изменить его, проделайте предыдущие пункты и проверьте свои выводы.
# 
# <font color='saddlebrown'>**[5. Общие выводы](#num5)**</font>
# 
# 
# 

# # Выполнение проекта

# <a name="num1"></a>
# ## Изучение исходных данных

# In[1]:


# Загружаем библиотеки
import pandas as pd
import numpy as np
import math as mth
from scipy import stats as stats
import datetime as dt
from matplotlib.pyplot import figure
import warnings
warnings.filterwarnings('ignore')
import matplotlib.pyplot as plt
from pandas.plotting import register_matplotlib_converters
import matplotlib as mpl
import matplotlib.pylab as pylab
import seaborn as sns
from matplotlib.ticker import FuncFormatter
import seaborn as sns
from plotly import graph_objects as go


# In[2]:


data_before = pd.read_csv('https://code.s3.yandex.net/datasets/logs_exp.csv', sep = '\t')


data_before.head(10)


# In[3]:


data_before.info()


# In[4]:


pd.set_option('display.float_format', lambda x: '%.3f' % x)


# In[5]:


data_before.describe()


# In[6]:


data_before.shape


# In[7]:


# Проверим наличие дубликатов
data_before.duplicated().sum()


# In[8]:


data = data_before.drop_duplicates()


# In[9]:


data.info()


# <a name="num2"></a>
# ## Предобработка данных

# ### Заменим названия столбцов на удобные для работы

# In[10]:


# Переименуем столбцы
data = data.rename(columns= {'EventName': 'event_name', 'DeviceIDHash':'user_id',                                     'EventTimestamp':'event_timestamp', 'ExpId':'experiment_id' })
data.head(3)


# ### Проверим пропуски и типы данных. Откорректием, если нужно

# In[11]:


pd.DataFrame(round(data.isna().mean()*100,)).style.background_gradient('BuPu') 


# ### Добавим столбец даты и времени, а также отдельный столбец дат

# In[12]:


data['event_time'] = pd.to_datetime(data['event_timestamp'], unit='s')
data.info()


# In[13]:


data['date'] = data['event_time'].astype('datetime64[D]')


# In[14]:


data.head(3)


# **`ВЫВОД`**: 
# <div style="border:solid orange 2px; padding: 20px"> 
# 
# В исходном датасете  244126 строк и 4 столбца.
#                  
#     
# После того, как изучили датасеты, выявили следующие первичные отклонения:
#      
# 1) Заменили названия столбцов. Добавили два новых столбца- с датой и временем события. 
# 2) `date`- не соответствует тип колонки object. Поменяли на datetime \
# 3) Удалили 413 дубликатов или 0,17%.\
# 4) Пропуски не выявлены.    
# </div>

# ### Сколько всего событий в логе?

# In[15]:


print('Всего событий в логе:', len(data['event_name']))

event_count = data.groupby('event_name').agg({'date':'count'}).reset_index()                      .sort_values(by='date', ascending=False)
print('Количество отслеживаемых событий:', len(event_count))


# <span class="mark">**Наблюдение:**</span> В логе всего 243 713 событий (49%) и 5 видов событий.

# ###  Сколько всего пользователей в логе?

# In[16]:


users_before = data['user_id'].nunique()
print('Всего пользователей в логе:', users_before )


# In[17]:


# Количество пользователей в разрезе группы
group_count = data.groupby('experiment_id').agg({'user_id':'nunique'}).reset_index()
group_count.columns = ['Группа', 'Кол-во пользователей']
group_count.style.bar(subset=['Кол-во пользователей'], color='#5fd6d6')


# In[18]:


# Вывод групп
print('Кол-во пользователей в группе 246:', group_count.iloc[0]['Кол-во пользователей'])
print('Кол-во пользователей в группе 247:', group_count.iloc[1]['Кол-во пользователей'])
print('Кол-во пользователей в группе 248:', group_count.iloc[2]['Кол-во пользователей'])


# <span class="mark">**Наблюдение:**</span> Всего в логе 7551 уникальных пользователей, которые распределены почти поровну на три группы:
# - группа 246: 2489
# - группа 247: 2520
# - группа 248: 2542

# ###  Сколько в среднем событий приходится на пользователя?

# In[23]:


# Рассчитаем среднее количество событий на пользователя
aver_events = data.groupby('user_id').agg({'event_name': 'count'}).mean().astype(int)

print('Cреднее количество событий на пользователя:', aver_events)


# <span class="mark">**Наблюдение:**</span> После очистки данных от аномалий было выявлено, что **в среднем один пользователь совершает 32 события**.

# ###  Данными за какой период вы располагаете? 

# - Найдите максимальную и минимальную дату. 
# - Постройте гистограмму по дате и времени. 
# - Можно ли быть уверенным, что у вас одинаково полные данные за весь период?
# - Технически в логи новых дней по некоторым пользователям могут «доезжать» события из прошлого — это может «перекашивать данные». 
# - Определите, с какого момента данные полные и отбросьте более старые. 
# - Данными за какой период времени вы располагаете на самом деле?

# In[24]:


# Минимальная дата
print('Минимальная дата:', data['event_time'].min())


# In[25]:


# Максимальная дата
print('Максимальная дата:', data['event_time'].max())


# Построим гистограмму по дате и времени

# In[26]:


# Построим гистограмму по дате
data.date.hist(figsize = (17,5), color='rebeccapurple', bins = 30, alpha=0.6)
plt.xlabel('Дата')
plt.title('Распределение количества событий по датам')
plt.ylabel('Кол-во событий')
plt.show()


# По графику видно, что с 25 по 31 июля событий в логах неправдоподобно мало, если сравнивать с августом. Посмотрим на данные за июль в процентном соотношении.

# In[27]:


data.shape


# In[28]:


#посчитаем процент событий с 25 по 31 июля от общего числа событий
events_july = data[data['date']<'2019-08-01 00:00:00']
print ('Всего событий за июль:',len(events_july))
print ('Процент событий за июль от всех данных:', round(len(events_july)/len(data)*100, 2))


# Как видно на графике, активность по событиям началась с 2019-08-01. Сделаем срез для удобства пользования и анализа актуального периода активностей поьзователя.

# In[29]:


# Фильтруем датасет и оставляем записи позже 2019-08-01
data = data.query('date >= "2019-08-01 00:00:00"')

print('Актуальный период активности пользователей с',  data['date'].min(),  'по',                                                data['date'].max())
print('Длительность периода составила:', data['date'].max()- data['date'].min())


# In[30]:


data.shape


# <span class="mark">**Наблюдение:**</span> После удаления периода, где практически не было активности со стороны пользователей, мы определили **активный период с 2019-08-01 по 2019-08-07  (6 дней)**.

# ### Много ли событий и пользователей вы потеряли, отбросив старые данные?

# In[31]:


print('Строк до обработки:', len(data_before))
print('Строк после обработки:', len(data))
print('Удалено строк:', len(data_before)-len(data))
print('Удалено:', '{:.2%}'.format((len(data_before) - len(data)) / len(data_before)))

#Посмотрим количество уникальных пользователей после чистки
print ('Количество уникальных пользователей после очищения:',data['user_id'].nunique())
print ('Количество удалённых пользователей:',users_before - data['user_id'].nunique())
print ('Процент удалённых пользователей:','{:.2%}'.format(round(users_before - data['user_id'].nunique())/users_before,2))
       
       


# <span class="mark">**Наблюдение:**</span> Было **удалено 0,23% (17) пользователей или 1.33%(3239) строк** по отношению к исходному датасету.
# 

# ### Проверьте, что у вас есть пользователи из всех трёх экспериментальных групп.

# In[32]:


# Количество пользователей в разрезе группы
group_count2 = data.groupby('experiment_id').agg({'user_id':'nunique'}).reset_index()
group_count2.columns = ['Группа', 'Кол-во пользователей']
# Вывод групп
print('Кол-во пользователей в группе 246:', group_count2.iloc[0]['Кол-во пользователей'])
print('Кол-во пользователей в группе 247:', group_count2.iloc[1]['Кол-во пользователей'])
print('Кол-во пользователей в группе 248:', group_count2.iloc[2]['Кол-во пользователей'])


# In[33]:


group_count2.style.bar(subset=['Кол-во пользователей'], color='#5fd6d6')


# <span class="mark">**Наблюдение:**</span> Пользователи присутствуют практически в равных пропорциях во всех трех группах.

# <a name="num3"></a>
# ## Воронка событий

# ### Посмотрим, какие события есть в логах, как часто они встречаются. Отсортируем события по частоте.

# In[34]:


# Виды событий отобразим в таблице по убыванию
types_event = data.event_name.value_counts().to_frame()
types_event.style.bar(subset=['event_name'], color='#5fd6d6')


# In[35]:


# Построим круговую диаграмму для определения доли каждого события

types_event.plot(y= 'event_name', kind="pie", figsize=(7, 7), autopct='%1.1f%%')
plt.legend(bbox_to_anchor=(0.6, 0, 0.6, 0.9)) # Расположение легенды на графике
plt.title('Доля распределения количества событий') # Название графика
plt.show()


# <span class="mark">**Наблюдение:**</span> В логе 5 видов событий, где лирером является `MainScreenAppear`. Также стоит заметить, что `PaymentScreenSuccessful`(успешная оплата) составила 22 349 раз (~11%), те каждое 9ое событие привело к оплате. 

# ### Посчитаем, сколько пользователей совершали каждое из этих событий. 

# - Отсортируем события по числу пользователей. 
# - Посчитаем долю пользователей, которые хоть раз совершали событие.

# In[36]:


# Отсортируем события по числу пользователей
users_event = data.groupby('event_name').agg({'user_id':'nunique'})                             .reset_index()                             .sort_values('user_id', ascending=False)
users_event.columns = ['Событие', 'Количество пользователей']

# Посчитаем уникальных пользователь из очищенной от аномалий базе

unique_users = len(data['user_id'].unique())
print('Всего пользователей в логе:', unique_users)

#Посчитаем долю пользователей, которые хоть раз совершали событие
users_event['Доля от всех пользователей(%)'] = users_event['Количество пользователей'] / unique_users * 100
users_event['Доля от всех пользователей(%)'] = round(users_event['Доля от всех пользователей(%)'],2)
users_event.sort_values(by='Доля от всех пользователей(%)', ascending=False)           .style.format({'Доля от всех пользователей(%)':'{:.2f}%'})
#users_event.style.bar(subset=['Доля от всех пользователей(%)'], color='#5fd6d6')
users_event


# In[37]:


# Построим круговую диаграмму для определения доли каждого события 
data.groupby('event_name').agg({'user_id':'nunique'})                                     .sort_values('user_id', ascending=False)                                     .plot(y= 'user_id', kind="pie", figsize=(7, 7), autopct='%1.1f%%')
plt.legend(bbox_to_anchor=(0.6, 0, 0.6, 0.9)) # Расположение легенды на графике
plt.title('Доля распределения количества пользователей в разрезе каждого события') # Название графика
plt.show()


# In[38]:


plt.figure(figsize=(10,7))
plt.title('Доля распределения количества пользователей в разрезе каждого события')
sns.barplot(data=users_event, x='Событие', y='Доля от всех пользователей(%)')
plt.xlabel('Событие')
plt.ylabel('Процент пользователей');


# <span class="mark">**Наблюдение:**</span> Согласно вышеуказанным расчетам видно, что до главного экрана приложения не дошло 1,5% пользователей, возможно были сбои или технические проблемы в приложении. Возможно стоит детализировать данный факт и уточнить в техподдерже вероятность сбоя. Также каждый 2ой пользователь дошел до успешной оплаты. 

# ### Предположим, в каком порядке происходят события.

# - Все ли они выстраиваются в последовательную цепочку? Их не нужно учитывать при расчёте воронки.

# Мы можем предположить, что воронка продаж для мобильного приложения будет следующей:
# - `MainScreenAppear` пользователь заходит на главную страницу сайта
#   - `OffersScreenAppear` пользователь переходит на тньересующий его товар
#     - `CartScreenAppear` пользователь добавляет товар в корзину
#       - `PaymentScreenSuccessful`  пользователь производит оплату

# Станица `Tutorial` является дополнением, но необязательным этапом в воронке продаж.

# In[39]:


# удалим из логов событие Tutorial
update_data_new = data.query('event_name != "Tutorial"')


# ### По воронке событий посчитаем, какая доля пользователей проходит на следующий шаг воронки (от числа пользователей на предыдущем).

# То есть для последовательности событий A → B → C посчитаем отношение числа пользователей с событием B к количеству пользователей с событием A, а также отношение числа пользователей с событием C к количеству пользователей с событием B.

# In[40]:


user_event = update_data_new.groupby('event_name').agg({'user_id': 'nunique'})                            .sort_values(by='user_id', ascending=False).reset_index()

user_event


# In[41]:


# еще раз построим таблицу с событиями и числом уникальных пользователей по очищенным данным
user_event = update_data_new.groupby('event_name').agg({'user_id': 'nunique'})                            .sort_values(by='user_id', ascending=False).reset_index()

# добавим столбец с конверсией
start= user_event.loc[0,'user_id']
user_event['Конверсия'] = round(user_event['user_id']/start*100, 1)
# Посчитаем конверсию от этапа к этапу
user_event['Конверсия в шаг %'] = round(user_event['user_id']/user_event['user_id'].shift()*100, 1)
#добавим вручную первое значение stage_conversion
user_event.loc[0, 'Конверсия в шаг %'] = round(user_event.loc[0,'user_id']/start*100, 1)

user_event


# In[42]:


#построим воронку с процентом перехода на каждый этап относительно начального 
fig = go.Figure(go.Funnel(
    x = user_event['user_id'], 
    y = user_event['event_name'],
    textinfo = "value+percent previous+percent initial"))
fig.update_layout(title='Воронка продаж мобильного приложения', title_x = 0.55)
fig.show();


# ### На каком шаге теряем больше всего пользователей?

# По итогам анализа воронки продаж мобильного приложения было выявлено следующее:
# 
# - Конверсия (расчет с первого шага):
# 
#      - пользователей, зашедших на главную страницу мы взяли за **100%**
#         - просмотр каталога товаров перешли почти **62%** пользователей
#             - перешли в корзину **50%**
#                 - оплата заказа **47%** пользователей .
# 
# 
# - Конверсия к шагу (расчет с предыдущего шага):
#      - пользователей, зашедших на главную страницу мы взяли за **100%**
#        - прешли в каталог из главной страницы **62%** прешли в каталог
#          - посмотрели каталог и добавили товар в корзину **81%** 
#            - произвели оплату после добавления товара в корзину **95%**
# 
# В итоге, больше всего пользователей потеряли с переходом "главная" -> "каталог"- около <span class="burk">38%</span>. 
# А вот с последующими событиями всё относительно неплохо: при переходе в корзину теряем около <span class="burk">19%</span> и при переходе к оплате лишь 5,2%.

# ### Какая доля пользователей доходит от первого события до оплаты?

# In[43]:


print('До оплаты доходит', round(user_event['user_id'].iloc[3]/user_event['user_id']                                                    .iloc[0], 2)*100, '% пользователей')


# <a name="num4"></a>
# ##  Pезультаты эксперимента 

# ### Сколько пользователей в каждой экспериментальной группе?

# In[44]:


# Построим сводную в разрезе каждой группы и события
split_groups = (
    update_data_new
    .groupby(['experiment_id', 'event_name']).agg({'user_id':'nunique'})
    .pivot_table(index='event_name', columns='experiment_id', values='user_id')
    .reset_index()
    .sort_values(246, ascending=False)
)

split_groups


# In[45]:


# Вывод групп ДО
print('Кол-во пользователей в группе 246:', group_count2.iloc[0]['Кол-во пользователей'])
print('Кол-во пользователей в группе 247:', group_count2.iloc[1]['Кол-во пользователей'])
print('Кол-во пользователей в группе 248:', group_count2.iloc[2]['Кол-во пользователей'])


# In[46]:


# Вывод групп ПОСЛЕ
update_data_new.groupby('experiment_id').agg({'user_id': 'nunique'})


# In[47]:


print('Всего пользователей в логе:', unique_users)
print ('Число пользователей после удаления:',update_data_new['user_id'].nunique())
print('Удалено пользователей:', unique_users- update_data_new['user_id'].nunique())


# ### Проверим, находят ли статистические критерии разницу между выборками 246 и 247.

# Есть 2 контрольные группы для А/А-эксперимента, чтобы проверить корректность всех механизмов и расчётов. 

# In[48]:


#запиишем количество пользователей каждой группы в отдельные переменные
group_A1 = update_data_new[update_data_new['experiment_id'] == 246]['user_id'].nunique()
group_A2 = update_data_new[update_data_new['experiment_id'] == 247]['user_id'].nunique()

#для дальнейшего проведения А/В теста
panel_B = update_data_new[update_data_new['experiment_id'] == 248]['user_id'].nunique()
panel_A = group_A1 + group_A2
#посмотрим разницу отношения пользователей группы А1 к группеА2
print('Разница между группой 246 и 247:','{:.2%}'.format((1-group_A1/group_A2)))


# <span class="mark">**Наблюдение:**</span> Отклонение между группой 246 и 247 равно 1,48%, что является статистически незначимым. Группы можно считать равными.

# ### Выберим самое популярное событие.

# - Посчитаем число пользователей, совершивших это событие в каждой из контрольных групп. 
# 

# In[49]:


#добавим столбец с общим количеством количеством пользователей в группах А1 и А2 в сводную таблицу split_groups - он понадовится нам для дальнейшего анализа
split_groups['groupA'] = split_groups[246] + split_groups[247]
split_groups


# - Посчитаем долю пользователей, совершивших это событие. 

# In[50]:


#Построим Stacked Funnel Plot with go.Funnel

fig = go.Figure()
fig.add_trace(go.Funnel(
    name = '246',
    y = split_groups['event_name'],
    x = split_groups[246],
    textinfo = "value+percent initial"))
fig.update_layout(title='Воронка продаж мобильного приложения в разрезе трех групп', title_x = 0.55)

fig.add_trace(go.Funnel(
    name = '247',
    orientation = "h",
    y = split_groups['event_name'],
    x = split_groups[247],
    textposition = "inside",
    textinfo = "value+percent initial"))

fig.add_trace(go.Funnel(
    name = '248',
    orientation = "h",
    y = split_groups['event_name'],
    x = split_groups[248],
    textposition = "inside",
    textinfo = "value+percent initial"))

fig.show()


# **Без сомнений, самой высокопосещаемой страницей во всех группах является - `MainScreenAppear`**

# <font size="3">
# <center><b>Подготовим данные для проведения А/A/Б теста</b></center>
# </font>
#     </div> 

# In[51]:


# Создадим новую сводную total_user

total_user = update_data_new.groupby('experiment_id')['user_id'].nunique()
total_user['groupA'] = total_user[246] + total_user[248]
total_user



# In[52]:


#напишем функцию. В качестве аргумента функции будем передовать названия сравниваемых групп
def stat_test(group1, group2):
    for i in split_groups.index:
        alpha = .05 # критический уровень статистической значимости


        successes = np.array([split_groups[group1][i],split_groups[group2][i]])
        trials = np.array([total_user[group1], total_user[group2]])

# пропорция успехов в первой группе:
        p1 = successes[0]/trials[0]

# пропорция успехов во второй группе:
        p2 = successes[1]/trials[1]

# пропорция успехов в комбинированном датасете:
        p_combined = (successes[0] + successes[1]) / (trials[0] + trials[1])

# разница пропорций в датасетах
        difference = p1 - p2 

# считаем статистику в ст.отклонениях стандартного нормального распределения
        z_value = difference / mth.sqrt(p_combined * (1 - p_combined) * (1/trials[0] + 1/trials[1]))

# задаем стандартное нормальное распределение (среднее 0, ст.отклонение 1)
        distr = stats.norm(0, 1)  

        p_value = round((1 - distr.cdf(abs(z_value))) * 2,3)
        print('Событие: ', split_groups['event_name'][i])
        print('p-value = ', p_value)
        print("alpha =",0.05)
        if p_value < alpha:
            print('Отвергаем Ho: между долями есть значимая разница')
            print()
        else:
            print('Не получилось отвергнуть Ho: нет оснований считать доли разными')
            print()


# <div class="alert alert-block alert-success"> 1) A1/A2 testing Посчитаем статистическую значимость различий между группами 246 и 247.</div>

# Сформулируем гипотезы. 
# 
# - Ho: различия между группами 246 и 247 нет. 
# - Ha: различие между группами 246 и 247 есть.
# 
# для расчета p-value= 0.05

# In[53]:


stat_test(246, 247)


# <span class="mark">**Наблюдение:**</span> После проведения A/A теста в разрезе каждого события отвергнуть нулевую гиптезу не удалось. **Статистической значимости между группами 246 и 247 не выявлено**. 

# - Проделаем то же самое для всех других событий (удобно обернуть проверку в отдельную функцию). Можно ли сказать, что разбиение на группы работает корректно?

# #### Аналогично поступите с группой с изменённым шрифтом.

# - Сравним результаты с каждой из контрольных групп в отдельности по каждому событию. 
# - Сравним результаты с объединённой контрольной группой. 
# 
# Какие выводы из эксперимента можно сделать?

# <div class="alert alert-block alert-success"> 2) A1/B testing Посчитаем статистическую значимость различий между группами 246 и 248. </div>

# Сформулируем гипотезы. 
# 
# - Ho: различия между группами 246 и 248 нет. 
# - Ha: различие между группами 246 и 248 есть.
# 
# для расчета p-value= 0.05

# In[54]:


stat_test(246, 248)


# <span class="mark">**Наблюдение:**</span> После проведения A1/B теста в разрезе каждого события отвергнуть нулевую гиптезу не удалось. **Статистической значимости между группами 246 и 248 не выявлено**. 

# <div class="alert alert-block alert-success"> 3) A2/B testing Посчитаем статистическую значимость различий между группами 247 и 248. </div>

# Сформулируем гипотезы. 
# 
# - Ho: различия между группами 247 и 248 нет. 
# - Ha: различие между группами 247 и 248 есть.
# 
# для расчета p-value= 0.05

# In[55]:


stat_test(247, 248)


# <span class="mark">**Наблюдение:**</span> После проведения A2/B теста в разрезе каждого события отвергнуть нулевую гиптезу не удалось. **Статистической значимости между группами 247 и 248 не выявлено**. 

# <div class="alert alert-block alert-success"> 4) A/B testing Посчитаем статистическую значимость различий между группами (246+247) и 248. </div>

# Сформулируем гипотезы. 
# 
# - Ho: различия между группами (246+247) и 248 нет. 
# - Ha: различие между группами (246+247) и 248 есть.
# 
# для расчета p-value= 0.05

# In[56]:


stat_test('groupA', 248)


# <span class="mark">**Наблюдение:**</span> После проведения A/B теста в разрезе каждого события отвергнуть нулевую гиптезу не удалось. **Статистической значимости между группами 246+247 и 248 не выявлено**. 

# ###  Какой уровень значимости вы выбрали при проверке статистических гипотез выше?

# - Посчитаем, сколько проверок статистических гипотез вы сделали. При уровне значимости 0.1 каждый десятый раз можно получать ложный результат. 
# - Какой уровень значимости стоит применить? 
# 
# Если вы хотите изменить его, проделайте предыдущие пункты и проверьте свои выводы.

# <span class="mark">**Наблюдение:**</span> Всего было проведено 16 экспериментов. Сравнивались группы А1/А2, А1/В, А2/В и А1+А2/В по каждому из четырех событий. При выборе статистической значимости 0.05 ни одна гитотеза не была отклонена.

# <a name="num5"></a>
# ## Общий вывод

# <div style="border:solid gray 2px; padding: 20px">        
# Изучив датасэт, в котором содержалось 244 126 строк и 4 столбца,  позволило определить следующие особенности в поведении пользователей:
# 
#     
# - <span class="mark">событийный анализ</span>
#     
#    - В логе 5 видов событий, где лирером является `MainScreenAppear`. Также стоит заметить, что `PaymentScreenSuccessful` (успешная оплата) составила 22 349 раз (~11%), те каждое 9ое событие привело к оплате; 
#    - в среднем на пользователя приходилось 28 событий; 
#    - пользователи присутствуют практически в равных пропорциях во всех трех группах.
#    
#     
# - <span class="mark">анализ воронки продаж</span>
#     - в среднем 47% пользователей от общего количества пользователей совершают покупку и производят успешную оплату в приложении.
#     - больше всего пользователей потеряли с переходом "главная" -> "каталог"- около <span class="burk">38%</span>. 
# А вот с последующими событиями всё относительно неплохо: при переходе в корзину теряем около <span class="burk">19%</span> и при переходе к оплате лишь 5,2%;
#     - страница Tutorial является дополнением, но необязательным этапом в воронке продаж и составила 0,4% от общего объёма событий.
#     
# - <span class="mark">А/А/Б тестирование</span>
#     
#     Целью проведения тестирования являлось определение уровня значимости введения дизайнерами нового шрифта в мобильном приложении.
#     
#     Группа 246 и 247 были со старыми шрифтами, а группа 248 с новыми. По итогам проведения 16 экспериментов и при выборе статистической значимости 0.05 ни одна гитотеза не была отклонена. Тестирования показали, что новые шрифты, которые показывали пользователям из группы Б никак не повлияли на поведение пользователей внутри приложения и доля пользователей, совершивших покупки осталась практически без изменений.
#     
#     <font color='green'>**Рекомендация компании:**</font>
#     В связи с отсутствием негативной реакции потребителей на изменение шрифта в мобильном приложении, компания с полной уверенностью может изменить старый шрифт на новый, но на бизнес-показатели это не повлияет.
# </div>

# In[ ]:




